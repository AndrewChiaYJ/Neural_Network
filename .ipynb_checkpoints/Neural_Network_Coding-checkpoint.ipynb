{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a14846-57ea-426d-99a6-0da4d970fb70",
   "metadata": {},
   "source": [
    "# Neural Network Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea0ffb-9795-469a-98f7-902ce2b166fa",
   "metadata": {},
   "source": [
    "# Building a simple Neural Network Model From Scratch (Without Using any Library)\n",
    "\n",
    "Source: [How to Create a Simple Neural Network in Python](https://www.kdnuggets.com/2018/10/simple-neural-network-python.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6909d-7fcb-4108-8481-095a5fcd0ea4",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th rowspan=\"4\">Training Data</th>\n",
    "      <th colspan=\"3\">Input</th>\n",
    "      <th rowspan=\"2\">Output</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th><i>x<sub>1</sub></i></th>\n",
    "      <th><i>x<sub>2</sub></i></th>\n",
    "      <th><i>x<sub>3</sub></i></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Training data 1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Training data 2</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Training data 3</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Training data 4</td>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>New Situation</b></td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>?</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "871b4b02-9f32-4059-a5b5-685e313b9bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53316528],\n",
       "       [0.69187711],\n",
       "       [0.31551563]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8808cb4b-c990-4319-b769-c002d4acc39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Randomly Generated Weights: \n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "Ending Weights After Training: \n",
      "[[0.54818715]\n",
      " [2.5547951 ]\n",
      " [9.69456358]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User Input One:  1\n",
      "User Input Two:  0\n",
      "User Input Three:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering New Situation:  1 0 0\n",
      "New Output data: \n",
      "[0.63371489]\n",
      "Wow, we did it!\n"
     ]
    }
   ],
   "source": [
    "# Create a neural network class\n",
    "\n",
    "# import numpy library\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self):\n",
    "        # seeding for random number generation\n",
    "        np.random.seed(1)\n",
    "\n",
    "        # converting weights to a 3 x 1 matrix with values from -1 to 1 and mean of 0\n",
    "        # np.random.random((3,1)) is to generate a 3 x 1 matrix, and randomly filled in any float numbers between 0 to 1\n",
    "        # multiple that by 2 is to expand the number range to 0 - 2, and -1 is to translate downwards by 1 so that the range is within -1 and 1\n",
    "        self.synaptic_weights = 2 * np.random.random((3,1))-1\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        # applying the sigmoid function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        # computing derivative to the sigmoid function\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train (self, training_inputs, training_outputs, training_iterations):\n",
    "\n",
    "        # training the model to make accurate predictions while adjusting weights continually\n",
    "        for iteration in range(training_iterations):\n",
    "\n",
    "            # siphon the training data via the neuron\n",
    "            output = self.think(training_inputs)\n",
    "\n",
    "            # computing error rate for back propagation\n",
    "            error = (training_outputs - output)**2\n",
    "\n",
    "            # performing weight adjustment\n",
    "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "\n",
    "            self.synaptic_weights += adjustments\n",
    "\n",
    "    def think (self, inputs):\n",
    "        # passing the inputs (converted into floats) via the neuron to get output\n",
    "        inputs = inputs.astype(float)\n",
    "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
    "        return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # initializing the neuron class\n",
    "    neural_network = NeuralNetwork()\n",
    "\n",
    "    print(\"Beginning Randomly Generated Weights: \")\n",
    "    print(neural_network.synaptic_weights)\n",
    "\n",
    "    # training data consisting of 4 examples -- 3 input values and 1 output\n",
    "    training_inputs = np.array([[0,0,1],\n",
    "                                [1,1,1],\n",
    "                                [1,0,1],\n",
    "                                [0,1,1]])\n",
    "    training_outputs = np.array([[0,1,1,0]]).T\n",
    "\n",
    "    # training taking place\n",
    "    neural_network.train(training_inputs, training_outputs, 15000)\n",
    "\n",
    "    print(\"Ending Weights After Training: \")\n",
    "    print(neural_network.synaptic_weights)\n",
    "\n",
    "    user_input_one = str(input(\"User Input One: \"))\n",
    "    user_input_two = str(input(\"User Input Two: \"))\n",
    "    user_input_three = str(input(\"User Input Three: \"))\n",
    "    \n",
    "    print(\"Considering New Situation: \", user_input_one, user_input_two, user_input_three)\n",
    "    print(\"New Output data: \")\n",
    "    print(neural_network.think(np.array([user_input_one, user_input_two, user_input_three])))\n",
    "    print(\"Wow, we did it!\")\n",
    "                                \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3c06e-f9dc-41d0-a864-ed0dbdde04cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "264a3acd-3442-4c95-8fdb-5d57f0ab65e3",
   "metadata": {},
   "source": [
    "# How to build a Neural Network from scratch\n",
    "\n",
    "Source: [How to build a Neural Network from scratch](https://www.freecodecamp.org/news/building-a-neural-network-from-scratch/)\n",
    "\n",
    "2nd source: [Neural Network from Scratch Interactive](https://aegeorge42.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89954df8-6faa-42dd-8a18-bc96d83987d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c37ba1-0b9b-48c9-8533-5415ad8d0532",
   "metadata": {},
   "source": [
    "1st step: To initialize the parameters (2 parameters for each of neurons in each layer: Weight and Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64e08504-e10c-43fd-9b6b-e260b6459496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function of layer_dimension to hold the dimensions of each layer\n",
    "def init_params(layer_dims):\n",
    "    # seeding for random number generation\n",
    "    np.random.seed(3)\n",
    "    \n",
    "    # declare a dictionary called params to store parameters\n",
    "    params = {}\n",
    "\n",
    "    # run a for loop for every layers available\n",
    "    for l in range(1, len(layer_dims)):\n",
    "        \n",
    "        # Store the Weights Parameters with keys as W1, W2, etc.. and the values as follows:\n",
    "        # np.random.randn(layer_dims[l], layer_dims[l-1]) is to generate an array with layer_dims[l] x layer_dims[l-1] dimension\n",
    "        # filled with random float numbers sampled from a \"standard normal\" distribution (mean 0, variance 1) - a rnage of 1 to -1\n",
    "        # multiply by 0.01 to restrict the range of values from -0.01 to 0.01\n",
    "        params['W'+str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
    "        \n",
    "        # Store the Bias Parameters with keys as b1, b2, etc.. and the values as follows:\n",
    "        # np.zeros((layer_dims[l], 1)) is to generate an array with layer_dims[l] x 1 dimension\n",
    "        # filled with 0\n",
    "        params['b'+str(l)] = np.zeros((layer_dims[l], 1))\n",
    "\n",
    "    # return the params dictionary after storing all the paramters of every layer dimension\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff529fe9-6755-44d3-91cc-90d5d3f7792e",
   "metadata": {},
   "source": [
    "2nd step: Define the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45a53238-cdda-4ebe-9d4c-6f33755c7fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sigmoid function as an activation function\n",
    "# Sigmoid function takes input with discrete values and gives a value which lies between zero and one. Its purpose is to convert the linear outputs to non-linear outputs. \n",
    "# Z (linear hypothesis) - Z = W*X + b , \n",
    "# W - weight matrix, b- bias vector, X- Input \n",
    "\n",
    "def sigmoid(Z):\n",
    "    # Define the sigmoid formula, where the Input Z is being made as -Z\n",
    "    A = 1/(1+np.exp(np.dot(-1, Z)))\n",
    "    # Store cache values because we need them for implementing back propagation\n",
    "    cache = (Z)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21364d8d-c668-4a66-9ce7-0bd1bc6e8b08",
   "metadata": {},
   "source": [
    "3rd step: Write the code for forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66ae9ca6-9cf4-4e08-a36d-d1937de18b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for forward propagation\n",
    "def forward_prop(X, params):\n",
    "\n",
    "    A = X # input to first layer i.e. training data\n",
    "    caches = [] # initiate a list for cache\n",
    "    L = len(params)//2\n",
    "    # Loop through all layers\n",
    "    for l in range(1, L+1):\n",
    "        # Store the previous layer's input into this variable \n",
    "        A_prev = A \n",
    "\n",
    "        # Linear Hypothesis (Do this Z = W*X + b)\n",
    "        Z = np.dot(params['W'+str(l)], A_prev) + params['b'+str(l)] \n",
    "\n",
    "        # Storing the linear cache above\n",
    "        linear_cache = (A_prev, params['W'+str(l)], params['b'+str(l)]) \n",
    "\n",
    "        # Applying sigmoid on linear hypothesis\n",
    "        A, activation_cache = sigmoid(Z) \n",
    "\n",
    "         # storing the both linear and activation cache\n",
    "        cache = (linear_cache, activation_cache)\n",
    "        caches.append(cache)\n",
    "\n",
    "    return A, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68adcaf-73ce-468a-8dae-7f2b398cfc57",
   "metadata": {},
   "source": [
    "4th step: Define cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72b60c98-ef7d-4049-b858-dd755ece76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cost function\n",
    "# As the value of the cost function decreases, the performance of our model becomes better.\n",
    "# The value of the cost function can be minimized by updating the values of the parameters of each of the layers in the neural network. \n",
    "def cost_function(A, Y):\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Gradient Descent formula\n",
    "    cost = (-1/m)*(np.dot(np.log(A), Y.T) + np.dot(log(1-A), 1-Y.T)) \n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b251361-271e-456c-b46e-a97e24bc348d",
   "metadata": {},
   "source": [
    "5th step: To define backpropagation step for a single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "098f53f0-e0e8-433a-ade7-f2e860eec252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for backpropagation step for 1 single layer\n",
    "def one_layer_backward(dA, cache):\n",
    "    # Take the cache from forward propagation as input\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    Z = activation_cache\n",
    "    # The derivative of the sigmoid function applied to the activation cache\n",
    "    dZ = dA*sigmoid(Z)*(1-sigmoid(Z)) \n",
    "\n",
    "    A_prev, W, b = linear_cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    # Calculate dW, db and dA_prev, which are the derivatives of cost function with respect the weights, biases and previous activation respectively\n",
    "    dW = (1/m)*np.dot(dZ, A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6040c44-0453-492e-8527-fc214686e857",
   "metadata": {},
   "source": [
    "6th step: Implement backpropagation for the entire neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a1f949e-c7d0-4ae3-aa4a-c17405e16ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(AL, Y, caches):\n",
    "    # Create a dictionary for mapping gradients to each layer\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "\n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1-Y, 1-AL))\n",
    "\n",
    "    current_cache = caches[L-1]\n",
    "    grads['dA'+str(L-1)], grads['dW'+str(L-1)], grads['db'+str(L-1)] = one_layer_backward(dAL, current_cache)\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = one_layer_backward(grads[\"dA\" + str(l+1)], current_cache)\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1525b-bc63-4c54-ab13-3039e243cd99",
   "metadata": {},
   "source": [
    "7th step: Use gradient values to update the parameters for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aed1b648-eeda-4b49-9446-0bd3b3edbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to update the parameters\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters['W'+str(l+1)] = parameters['W'+str(l+1)] -learning_rate*grads['W'+str(l+1)]\n",
    "        parameters['b'+str(l+1)] = parameters['b'+str(l+1)] -  learning_rate*grads['b'+str(l+1)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa9d379-6385-4dac-a8ff-4b1cc911b404",
   "metadata": {},
   "source": [
    "Last step: To Train the neural network by putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cd8416f-1a34-44d9-bffd-99442d7e3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train\n",
    "def train(X, Y, layer_dims, epochs, lr):\n",
    "    params = init_params(layer_dims)\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        Y_hat, caches = forward_prop(X, params)\n",
    "        cost = cost_function(Y_hat, Y)\n",
    "        cost_history.append(cost)\n",
    "        grads = backprop(Y_hat, Y, caches)\n",
    "\n",
    "        params = update_parameters(params, grads, lr)\n",
    "\n",
    "\n",
    "    return params, cost_history\n",
    "\n",
    "# This function will go through all the functions step by step for a given number of epochs. \n",
    "# After finishing that, it will return the final updated parameters and the cost history. \n",
    "# Cost history can be used to evaluate the performance of your network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aeb2e2-a19f-42e5-8130-408604f719b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91edd17b-3a94-483d-8e0a-ebcb551701e0",
   "metadata": {},
   "source": [
    "# Your First Deep Learning Project in Python with Keras Step-by-Step\n",
    "\n",
    "Source: [\"Your First Deep Learning Project in Python with Keras Step-by-Step\"](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2407a98-eefd-404f-9342-c89cb74e1c6a",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4340191e-1c22-4f5a-8441-ae9dfec29b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd4de21-52b9-4860-8710-0aded2798383",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3247c321-8893-477b-a15a-dd17a317b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt('./pima-indians-diabetes.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8] # There are 8 input features in this dataset\n",
    "y = dataset[:,8]   # There are 1 output variable in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf2ed5d-a11a-4086-b8ca-b4d406b30de2",
   "metadata": {},
   "source": [
    "## Define Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe81466-ef3e-4410-b9f3-8909ba36dfc2",
   "metadata": {},
   "source": [
    "To define keras model, 1st need to get the number of input features correct.\n",
    "Then, need to decide on the number of layers and types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02bf8017-f4bf-49b6-9c69-50d5bbc98a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, we using 3 layer network.\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add 1st hidden Dense layer with 12 nodes, using relu activation function, and expecting input of 8 variables.\n",
    "model.add(Dense(12, input_shape=(8,), activation = 'relu')) \n",
    "\n",
    "# Add 2nd hidden Dense layer with 8 nodes, using relu activation function\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "\n",
    "# Add the Output layer with 1 node, using sigmoid activation function\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654da33-e284-4289-aad4-4318e17be178",
   "metadata": {},
   "source": [
    "## Compile Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed74b299-4816-4e8f-be23-5810d524550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Keras Model\n",
    "# Need to specify:\n",
    "# 1) the loss function to use to evaluate a set of weights\n",
    "# 2) the optimizer used to search through different weights for the network\n",
    "# 3) any optional metrics you want to collect and report during training\n",
    "# In this example, uses the loss function of binary_crossentropy, adam optimizer, and accuracy metrics.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75972ef7-47e7-4800-9a0a-c29e3a2af4e3",
   "metadata": {},
   "source": [
    "## Fit Keras Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a832bd9b-ae8a-4d34-83fc-9d94a0c59210",
   "metadata": {},
   "source": [
    "Train the model. Training occurs over epochs, and each epoch is split into batches based on the chosen batch size.\n",
    "- Epoch: One pass through all of the rows in the training dataset\n",
    "- Batch: One or more samples considered by the model within an epoch before weights are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4bbb44f-1180-4c36-b59c-209b350f2731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "Epoch 2/150\n",
      "Epoch 3/150\n",
      "Epoch 4/150\n",
      "Epoch 5/150\n",
      "Epoch 6/150\n",
      "Epoch 7/150\n",
      "Epoch 8/150\n",
      "Epoch 9/150\n",
      "Epoch 10/150\n",
      "Epoch 11/150\n",
      "Epoch 12/150\n",
      "Epoch 13/150\n",
      "Epoch 14/150\n",
      "Epoch 15/150\n",
      "Epoch 16/150\n",
      "Epoch 17/150\n",
      "Epoch 18/150\n",
      "Epoch 19/150\n",
      "Epoch 20/150\n",
      "Epoch 21/150\n",
      "Epoch 22/150\n",
      "Epoch 23/150\n",
      "Epoch 24/150\n",
      "Epoch 25/150\n",
      "Epoch 26/150\n",
      "Epoch 27/150\n",
      "Epoch 28/150\n",
      "Epoch 29/150\n",
      "Epoch 30/150\n",
      "Epoch 31/150\n",
      "Epoch 32/150\n",
      "Epoch 33/150\n",
      "Epoch 34/150\n",
      "Epoch 35/150\n",
      "Epoch 36/150\n",
      "Epoch 37/150\n",
      "Epoch 38/150\n",
      "Epoch 39/150\n",
      "Epoch 40/150\n",
      "Epoch 41/150\n",
      "Epoch 42/150\n",
      "Epoch 43/150\n",
      "Epoch 44/150\n",
      "Epoch 45/150\n",
      "Epoch 46/150\n",
      "Epoch 47/150\n",
      "Epoch 48/150\n",
      "Epoch 49/150\n",
      "Epoch 50/150\n",
      "Epoch 51/150\n",
      "Epoch 52/150\n",
      "Epoch 53/150\n",
      "Epoch 54/150\n",
      "Epoch 55/150\n",
      "Epoch 56/150\n",
      "Epoch 57/150\n",
      "Epoch 58/150\n",
      "Epoch 59/150\n",
      "Epoch 60/150\n",
      "Epoch 61/150\n",
      "Epoch 62/150\n",
      "Epoch 63/150\n",
      "Epoch 64/150\n",
      "Epoch 65/150\n",
      "Epoch 66/150\n",
      "Epoch 67/150\n",
      "Epoch 68/150\n",
      "Epoch 69/150\n",
      "Epoch 70/150\n",
      "Epoch 71/150\n",
      "Epoch 72/150\n",
      "Epoch 73/150\n",
      "Epoch 74/150\n",
      "Epoch 75/150\n",
      "Epoch 76/150\n",
      "Epoch 77/150\n",
      "Epoch 78/150\n",
      "Epoch 79/150\n",
      "Epoch 80/150\n",
      "Epoch 81/150\n",
      "Epoch 82/150\n",
      "Epoch 83/150\n",
      "Epoch 84/150\n",
      "Epoch 85/150\n",
      "Epoch 86/150\n",
      "Epoch 87/150\n",
      "Epoch 88/150\n",
      "Epoch 89/150\n",
      "Epoch 90/150\n",
      "Epoch 91/150\n",
      "Epoch 92/150\n",
      "Epoch 93/150\n",
      "Epoch 94/150\n",
      "Epoch 95/150\n",
      "Epoch 96/150\n",
      "Epoch 97/150\n",
      "Epoch 98/150\n",
      "Epoch 99/150\n",
      "Epoch 100/150\n",
      "Epoch 101/150\n",
      "Epoch 102/150\n",
      "Epoch 103/150\n",
      "Epoch 104/150\n",
      "Epoch 105/150\n",
      "Epoch 106/150\n",
      "Epoch 107/150\n",
      "Epoch 108/150\n",
      "Epoch 109/150\n",
      "Epoch 110/150\n",
      "Epoch 111/150\n",
      "Epoch 112/150\n",
      "Epoch 113/150\n",
      "Epoch 114/150\n",
      "Epoch 115/150\n",
      "Epoch 116/150\n",
      "Epoch 117/150\n",
      "Epoch 118/150\n",
      "Epoch 119/150\n",
      "Epoch 120/150\n",
      "Epoch 121/150\n",
      "Epoch 122/150\n",
      "Epoch 123/150\n",
      "Epoch 124/150\n",
      "Epoch 125/150\n",
      "Epoch 126/150\n",
      "Epoch 127/150\n",
      "Epoch 128/150\n",
      "Epoch 129/150\n",
      "Epoch 130/150\n",
      "Epoch 131/150\n",
      "Epoch 132/150\n",
      "Epoch 133/150\n",
      "Epoch 134/150\n",
      "Epoch 135/150\n",
      "Epoch 136/150\n",
      "Epoch 137/150\n",
      "Epoch 138/150\n",
      "Epoch 139/150\n",
      "Epoch 140/150\n",
      "Epoch 141/150\n",
      "Epoch 142/150\n",
      "Epoch 143/150\n",
      "Epoch 144/150\n",
      "Epoch 145/150\n",
      "Epoch 146/150\n",
      "Epoch 147/150\n",
      "Epoch 148/150\n",
      "Epoch 149/150\n",
      "Epoch 150/150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3403aaa80>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "# Epoch: How many times does the dataset need to be go through for the training\n",
    "# Batch_size: Number of dataset rows that are considered before model weights are updated within each epoch.\n",
    "\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc27351-7d9c-4e31-a6da-dd7f99ee1825",
   "metadata": {},
   "source": [
    "## Evaluate Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "96a2c269-39e9-4111-84c4-ea734d786316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7763 - loss: 0.4743\n",
      "Accuracy: 79.56\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using evaluate () function and give an idea of how well the modelling on the dataset have been done\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9574c09-c270-4790-bc59-4edd67345d10",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b66b4928-c821-493a-9afe-daf4888e4b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step\n",
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h6/w8bbmwbn4jjfk47rlp6b38nc0000gn/T/ipykernel_3404/2803751289.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))\n"
     ]
    }
   ],
   "source": [
    "# make class predictions with the model\n",
    "predictions = (model.predict(X) > 0.5).astype(int)\n",
    "# summarize the first 5 cases\n",
    "for i in range(5):\n",
    "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d6e94e4-acff-44dd-86e5-49bba463b7bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1561f-5a59-4bd7-aa5a-23d7e04668d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b57269-7587-4c8a-a4c6-663c88fd7d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
